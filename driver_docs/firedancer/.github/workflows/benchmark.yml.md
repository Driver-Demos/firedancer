<!--------------------------------------------------------------------------------->
<!-- IMPORTANT: This file is auto-generated by Driver (https://driver.ai). -------->
<!-- Manual edits may be overwritten on future commits. --------------------------->
<!--------------------------------------------------------------------------------->

GitHub Actions workflow for benchmarking ledger backtests, comparing performance metrics, and posting results.

# Purpose
This GitHub Actions workflow file automates the process of benchmarking a software component called "Ledger Backtest." It is triggered by a `workflow_call` or `workflow_dispatch` event and requires a GitHub token for posting comments. The workflow defines permissions for reading contents and writing to issues and pull requests. It includes a job named `benchmark` that runs on a self-hosted machine with specific labels and environment variables. The job consists of several steps: checking out the current commit, setting up dependencies, configuring huge pages, and running a series of make commands to build the project. It performs baseline and new benchmarks by executing a script and logs the results. The workflow calculates performance metrics, such as ratios and percentage changes, and generates a `benchmark.json` file. It fetches the `gh-pages` branch and publishes the benchmark results using a custom tool. If the event is a pull request or issue comment, it posts a comment with a Markdown table comparing baseline and new performance metrics.
# Content Summary
The provided configuration file is a GitHub Actions workflow file named "Benchmark Ledger Backtest." This file defines a workflow that is triggered by a `workflow_call` or `workflow_dispatch` event. The workflow is designed to perform benchmarking tasks on a software project, specifically comparing the performance of a baseline version against new changes.

Key technical details include:

1. **Inputs and Permissions**: 
   - The workflow accepts three inputs: `machine`, `extras`, and `github-token`. The `machine` and `extras` inputs have default values, while the `github-token` is required for posting comments.
   - The workflow has permissions to read contents and write to issues and pull requests.

2. **Job Configuration**:
   - The workflow contains a single job named `benchmark` that runs on a self-hosted runner with specific labels and a timeout of 15 minutes.
   - Environment variables are set using the inputs provided.

3. **Steps in the Job**:
   - The job begins by checking out the current commit and setting up dependencies and environment configurations.
   - It runs a series of commands to compile the code and perform baseline and new benchmarks using a script `run_ledger_backtest.sh`.
   - The results of these benchmarks, such as `SEC_SLOT`, `TOTAL_ELAPSED`, `SNAPSHOT_LOAD`, and `DEFAULT_MEM`, are extracted and stored in environment variables.

4. **Benchmark Comparison**:
   - The workflow calculates performance ratios and percentage changes between the baseline and new benchmarks.
   - It generates a `benchmark.json` file containing formatted benchmark results.

5. **Publishing and Commenting**:
   - The workflow fetches the `gh-pages` branch and uses a GitHub Action to publish benchmark results.
   - If the event is a pull request or issue comment, it posts a comment with a Markdown table comparing the baseline and new benchmark results, highlighting changes and using icons to indicate significant changes.

This workflow is essential for developers to automate the process of performance testing and to ensure that new changes do not degrade the performance of the software.

---
Made with ❤️ by [Driver](https://www.driver.ai/)