# Purpose
The provided content is a detailed block diagram and accompanying notes that describe a transaction filtering pipeline for block production, specifically within a high-performance computing environment. This file appears to be a technical document, likely in markdown format, that outlines the architecture and operational flow of a system designed to process and filter network transactions efficiently. The diagram illustrates the flow of raw packets from network interfaces through various processing stages, including signature verification, deduplication, and metadata handling, ultimately leading to block packing and distribution to an Agave validator. The document emphasizes the use of high core count x86 CPUs, NUMA node optimization, and dynamic component management, such as hotswapping and live monitoring, to ensure robust and scalable operations. This file is crucial for developers and system architects as it provides a comprehensive overview of the system's design, enabling them to understand, maintain, and optimize the transaction filtering pipeline within the codebase.
# Content Summary
The document describes the transaction filtering pipeline for block production, specifically focusing on the Frankendancer Filtering system as of September 2023. This system is designed to handle high-throughput transaction processing using a combination of advanced networking and computing techniques. The pipeline begins with raw packet intake from various network interfaces, including AF_XDP, sockets, ENA, IO uring, DPDK, and others, ideally positioned near the NUMA node corresponding to the ingress processing core for optimal performance.

The architecture is built around a series of workspaces (wksp) and cores, each responsible for specific tasks such as NIC/QUIC handling, signature verification (SIG VERIFY), and deduplication tagging (DEDUP TAG). These components are designed to work in parallel, leveraging high core count x86 CPUs and large page-backed shared memory objects to minimize NUMA node interactions. The system supports dynamic inspection, monitoring, and debugging through named workspaces, allowing for non-invasive capture of component inputs and facilitating live component hotswapping to manage load changes or hardware failures.

The pipeline's design allows for flexible execution models, supporting single-process, multi-threaded, or multi-process configurations. The current implementation is single-process with named workspaces, but it can be refactored into a multi-process model if needed. The communication path from network interfaces to the Agave validator is designed to be reliable, ensuring simplicity and reproducibility.

The document also highlights the potential for future enhancements, such as moving components to FPGA, ASIC, or GPU acceleration, provided they adhere to the Tango ABI. The deduplication process is performed after signature verification due to encryption requirements, utilizing the Tango metadata signature field for transaction tagging. This approach supports horizontal scaling and parallelization, allowing for efficient handling of high-bandwidth NICs and high core count environments. The system is designed to produce cryptographically secure outputs as part of the SHA-512 computation, with the flexibility to use alternative hashing algorithms if necessary.
